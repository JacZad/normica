import streamlit as st
import os
import datetime
from typing import List, Dict, Any

# Import Langchain
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import MarkdownTextSplitter
from langchain.chains import create_retrieval_chain
from langchain.chains.history_aware_retriever import create_history_aware_retriever
from langchain_core.documents import Document

# --- NarzÄ™dzia ---
@tool
def font_size_calculator(distance: float) -> str:
    """
    Oblicza zalecanÄ… wysokoÅ›Ä‡ czcionki w milimetrach na podstawie odlegÅ‚oÅ›ci obserwacji w milimetrach.
    UÅ¼ywaj tego narzÄ™dzia, gdy uÅ¼ytkownik pyta o wielkoÅ›Ä‡ czcionki, rozmiar tekstu lub podobne kwestie zwiÄ…zane z odlegÅ‚oÅ›ciÄ….
    """
    if distance <= 0:
        return "OdlegÅ‚oÅ›Ä‡ musi byÄ‡ wiÄ™ksza od zera."
    height = distance * 2.2 / 180
    return f"Dla odlegÅ‚oÅ›ci {distance} mm zalecana wysokoÅ›Ä‡ czcionki to {height:.2f} mm."

@tool
def get_current_date() -> str:
    """
    Zwraca aktualnÄ… datÄ™ w formacie YYYY-MM-DD.
    UÅ¼ywaj, gdy uÅ¼ytkownik pyta o dzisiejszÄ… datÄ™.
    """
    return datetime.date.today().strftime('%Y-%m-%d')

# --- Klasa Chatbota ---
class NormicaChatbot:
    def __init__(self, model_name="gpt-4o", temperature=0):
        self.llm = ChatOpenAI(model_name=model_name, temperature=temperature)
        self.vector_store = self._get_vector_store()
        self._setup_agent()

    def _get_vector_store(self):
        """Tworzy lub wczytuje bazÄ™ wektorowÄ… FAISS."""
        FAISS_INDEX_PATH = "faiss_index"
        if os.path.exists(FAISS_INDEX_PATH):
            st.info("WczytujÄ™ bazÄ™ wiedzy...")
            return FAISS.load_local(FAISS_INDEX_PATH, OpenAIEmbeddings(), allow_dangerous_deserialization=True)
        
        st.info("TworzÄ™ nowÄ… bazÄ™ wiedzy z dokumentu normy. To moÅ¼e chwilÄ™ potrwaÄ‡...")
        with open("en301549.md", "r", encoding="utf-8") as f:
            norm_text = f.read()
        
        text_splitter = MarkdownTextSplitter(chunk_size=1000, chunk_overlap=100)
        docs = [Document(page_content=x) for x in text_splitter.split_text(norm_text)]
        
        vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())
        vector_store.save_local(FAISS_INDEX_PATH)
        st.success("Baza wiedzy zostaÅ‚a pomyÅ›lnie utworzona.")
        return vector_store

    def _setup_agent(self):
        """Konfiguracja agenta LangChain z narzÄ™dziami i RAG."""
        retriever = self.vector_store.as_retriever(search_kwargs={"k": 5})

        # 1. NarzÄ™dzie do wyszukiwania w normie
        @tool
        def norm_search(query: str) -> List[Dict[str, Any]]:
            """
            Przeszukuje dokumentacjÄ™ normy EN 301 549 w poszukiwaniu odpowiedzi na pytanie uÅ¼ytkownika.
            UÅ¼ywaj tego narzÄ™dzia do odpowiadania na pytania dotyczÄ…ce wymagaÅ„, definicji, klauzul i innych treÅ›ci zawartych w normie.
            """
            docs = retriever.invoke(query)
            return [{"page_content": doc.page_content} for doc in docs]

        self.tools = [font_size_calculator, get_current_date, norm_search]
        
        # 2. Prompt systemowy dla agenta
        self.system_prompt = """
        JesteÅ› 'Normica', Å›wiatowej klasy ekspertem od europejskiej normy EN 301 549 dotyczÄ…cej dostÄ™pnoÅ›ci ICT.
        Twoim zadaniem jest odpowiadaÄ‡ na pytania uÅ¼ytkownikÃ³w, bazujÄ…c na dostarczonym kontekÅ›cie z normy oraz uÅ¼ywajÄ…c dostÄ™pnych narzÄ™dzi.

        DostÄ™pne narzÄ™dzia:
        - `font_size_calculator`: UÅ¼yj, gdy pytanie dotyczy obliczania wielkoÅ›ci czcionki.
        - `get_current_date`: UÅ¼yj, gdy pytanie dotyczy dzisiejszej daty.
        - `norm_search`: UÅ¼yj ZAWSZE, gdy pytanie dotyczy treÅ›ci normy EN 301 549 (wymagaÅ„, definicji, procedur, itp.). To Twoje gÅ‚Ã³wne ÅºrÃ³dÅ‚o wiedzy.

        Kroki postÄ™powania:
        1. Przeanalizuj pytanie uÅ¼ytkownika.
        2. JeÅ›li pytanie dotyczy ogÃ³lnej wiedzy o Å›wiecie, odpowiedz bezpoÅ›rednio.
        3. JeÅ›li pytanie dotyczy daty lub wielkoÅ›ci czcionki, uÅ¼yj odpowiedniego narzÄ™dzia.
        4. JeÅ›li pytanie dotyczy normy EN 301 549, ZAWSZE uÅ¼yj narzÄ™dzia `norm_search`, aby znaleÅºÄ‡ relevantne fragmenty.
        5. Na podstawie wynikÃ³w z `norm_search`, sformuÅ‚uj wyczerpujÄ…cÄ… i dokÅ‚adnÄ… odpowiedÅº. Cytuj kluczowe informacje i, jeÅ›li to moÅ¼liwe, odnoÅ› siÄ™ do numerÃ³w klauzul.
        6. JeÅ›li `norm_search` nie zwrÃ³ci wynikÃ³w, poinformuj uÅ¼ytkownika, Å¼e nie moÅ¼esz znaleÅºÄ‡ odpowiedzi w dokumencie.
        
        Odpowiadaj po polsku. BÄ…dÅº precyzyjny, pomocny i trzymaj siÄ™ faktÃ³w z dokumentu.
        """

        prompt = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad")
        ])

        agent = create_openai_functions_agent(self.llm, self.tools, prompt)
        self.agent_executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            verbose=False,
            handle_parsing_errors=True
        )

    def process_message(self, messages: List[Dict[str, Any]], user_input: str) -> Dict[str, Any]:
        """Przetwarzanie wiadomoÅ›ci uÅ¼ytkownika i generowanie odpowiedzi."""
        chat_history = [
            HumanMessage(content=msg["content"]) if msg["role"] == "user" else AIMessage(content=msg["content"])
            for msg in messages if msg["role"] in ["user", "assistant"]
        ]
        
        try:
            result = self.agent_executor.invoke({
                "input": user_input,
                "chat_history": chat_history
            })
            return {"role": "assistant", "content": result["output"]}
        except Exception as e:
            st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d agenta: {e}")
            return {"role": "assistant", "content": f"Przepraszam, wystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}"}

    def change_model(self, model_name: str, temperature: float = 0):
        """Zmiana modelu jÄ™zykowego."""
        self.llm = ChatOpenAI(model_name=model_name, temperature=temperature)
        self._setup_agent()

# --- Konfiguracja i UI Streamlit ---
st.set_page_config(page_title="Normica - Asystent dla normy EN 301 549", page_icon="ğŸ“˜", layout="centered")

if os.path.exists("normica_logo.svg"):
    st.image("normica_logo.svg", width=150)
else:
    st.title("ğŸ“˜ Normica")

st.subheader("Asystent dla normy EN 301 549")

if not os.getenv("OPENAI_API_KEY"):
    st.warning("âš ï¸ Brak klucza API OpenAI. Ustaw zmiennÄ… Å›rodowiskowÄ… OPENAI_API_KEY.")
    st.stop()

# Inicjalizacja chatbota i historii
if "chatbot" not in st.session_state:
    st.session_state.chatbot = NormicaChatbot()
    
if "messages" not in st.session_state:
    st.session_state.messages = []

# WyÅ›wietlanie historii
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# Panel boczny
with st.sidebar:
    st.subheader("ğŸ“ O aplikacji")
    st.write("""
    Normica to inteligentny asystent specjalizujÄ…cy siÄ™ w normie EN 301 549. 
    DziÄ™ki bazie wiedzy stworzonej z dokumentu normy, odpowiada na szczegÃ³Å‚owe pytania dotyczÄ…ce dostÄ™pnoÅ›ci ICT.
    """)
    st.divider()
    st.subheader("âš™ï¸ Konfiguracja")
    model_options = {
        "gpt-4o": "OpenAI GPT-4o",
        "gpt-4-turbo": "OpenAI GPT-4 Turbo",
        "gpt-3.5-turbo": "OpenAI GPT-3.5 Turbo"
    }
    selected_model = st.selectbox("Model jÄ™zykowy:", options=list(model_options.keys()), format_func=lambda x: model_options[x])
    temperature = st.slider("Temperatura (kreatywnoÅ›Ä‡):", min_value=0.0, max_value=1.0, value=0.0, step=0.1)
    
    if st.button("Zastosuj ustawienia"):
        st.session_state.chatbot.change_model(selected_model, temperature)
        st.success(f"Zmieniono model na {model_options[selected_model]}")
    
    st.divider()
    st.write("Â© 2025 Normica")

# Pole do wprowadzania tekstu
if prompt := st.chat_input("Zadaj pytanie o normÄ™ EN 301 549..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)
    
    with st.spinner("Normica analizuje normÄ™..."):
        response = st.session_state.chatbot.process_message(st.session_state.messages, prompt)
        st.session_state.messages.append(response)
        with st.chat_message("assistant"):
            st.write(response["content"])
