import streamlit as st
import os
import datetime
from typing import List, Dict, Any

# Import Langchain
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain.agents import create_openai_functions_agent
from langchain.agents import AgentExecutor

# Definicja narzÄ™dzia dla obliczania wielkoÅ›ci czcionki
@tool
def font_size_calculator(distance: float) -> str:
    """
    Oblicza zalecanÄ… wysokoÅ›Ä‡ czcionki w milimetrach na podstawie odlegÅ‚oÅ›ci obserwacji w milimetrach.
    WzÃ³r jest oparty o normÄ™ EN 301 549 dotyczÄ…cÄ… dostÄ™pnoÅ›ci ICT.
    
    Args:
        distance: OdlegÅ‚oÅ›Ä‡ obserwacji w milimetrach
    
    Returns:
        String opisujÄ…cy zalecanÄ… wielkoÅ›Ä‡ czcionki
    """
    if distance <= 0:
        return "OdlegÅ‚oÅ›Ä‡ musi byÄ‡ wiÄ™ksza od zera."
    
    height = distance * 2.2 / 180
    return f"Dla odlegÅ‚oÅ›ci {distance} mm zalecana wysokoÅ›Ä‡ czcionki to {height:.2f} mm."

@tool
def get_current_date() -> str:
    """
    Zwraca aktualnÄ… datÄ™ w formacie YYYY-MM-DD.
    To narzÄ™dzie jest przydatne do uzyskania bieÅ¼Ä…cej daty,
    np. dla datowania raportÃ³w lub planowania wydarzeÅ„.
    """
    return datetime.date.today().strftime('%Y-%m-%d')

# Klasa do zarzÄ…dzania chatem z rÃ³Å¼nymi modelami
class NormicaChatbot:
    def __init__(self, model_name="gpt-4o", temperature=0):
        self.llm = ChatOpenAI(model_name=model_name, temperature=temperature)
        self.tools = [font_size_calculator, get_current_date]
        self.system_prompt = """
        JesteÅ› asystentem eksperckim od normy EN 301 549 dotyczÄ…cej dostÄ™pnoÅ›ci ICT (Information and Communication Technology).
        Odpowiadasz na pytania uÅ¼ytkownikÃ³w, pomagasz interpretowaÄ‡ wymagania normy i doradzasz w kwestiach dostÄ™pnoÅ›ci.
        
        EN 301 549 to europejska norma dotyczÄ…ca wymagaÅ„ dostÄ™pnoÅ›ci dla produktÃ³w i usÅ‚ug ICT. 
        OkreÅ›la wymagania techniczne, ktÃ³re muszÄ… byÄ‡ speÅ‚nione, aby produkty i usÅ‚ugi ICT byÅ‚y dostÄ™pne dla wszystkich.
        
        Kiedy uÅ¼ytkownik zapyta o wielkoÅ›Ä‡ czcionki dla okreÅ›lonej odlegÅ‚oÅ›ci, uÅ¼yj funkcji font_size_calculator.
        MoÅ¼esz takÅ¼e obliczaÄ‡ wielkoÅ›Ä‡ czcionki samodzielnie uÅ¼ywajÄ…c wzoru: wysokoÅ›Ä‡ x (mm) = odlegÅ‚oÅ›Ä‡(mm) * 2.2 / 180
        
        Gdy uÅ¼ytkownik zapyta o aktualnÄ… datÄ™, uÅ¼yj funkcji get_current_date.
        
        Zawsze staraj siÄ™ byÄ‡ pomocny i udzielaÄ‡ precyzyjnych informacji.
        """
        self._setup_agent()
        
    def _setup_agent(self):
        """Konfiguracja agenta LangChain z narzÄ™dziami"""
        # Tworzenie szablonu promptu
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content=self.system_prompt),
            ("human", "{input}"),
            ("agent", "{agent_scratchpad}")
        ])
        
        # Tworzenie agenta z narzÄ™dziami
        self.agent = create_openai_functions_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )
        
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=False,
            handle_parsing_errors=True
        )
    
    def process_message(self, messages: List[Dict[str, Any]], user_input: str) -> Dict[str, Any]:
        """Przetwarzanie wiadomoÅ›ci uÅ¼ytkownika i generowanie odpowiedzi"""
        try:
            # PrzeksztaÅ‚cenie historii wiadomoÅ›ci na tekst dla kontekstu
            context = "\n".join([
                f"{msg['role']}: {msg['content']}" 
                for msg in messages[-10:] if msg['role'] != "system"
            ])
            
            # WywoÅ‚anie agenta z kontekstem i nowym pytaniem
            result = self.agent_executor.invoke({
                "input": f"Kontekst poprzedniej rozmowy:\n{context}\n\nAktualne pytanie: {user_input}"
            })
            
            return {"role": "assistant", "content": result["output"]}
        except Exception as e:
            return {"role": "assistant", "content": f"Przepraszam, wystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}"}
            
    def change_model(self, model_name: str, temperature: float = 0):
        """Zmiana modelu jÄ™zykowego"""
        self.llm = ChatOpenAI(model_name=model_name, temperature=temperature)
        self._setup_agent()

# Konfiguracja strony Streamlit
st.set_page_config(
    page_title="Normica - Asystent dla normy EN 301 549",
    page_icon="ğŸ“˜",
    layout="centered"
)

# WyÅ›wietlanie logo aplikacji
try:
    with open("normica_logo.svg", "r") as f:
        svg_content = f.read()
        st.image("normica_logo.svg", width=150)
except:
    # Fallback, gdyby nie znaleziono logo
    st.title("ğŸ“˜ Normica")

st.subheader("Asystent dla normy EN 301 549")

# Sprawdzenie klucza API
if not os.getenv("OPENAI_API_KEY"):
    st.warning("âš ï¸ Brak klucza API OpenAI. Ustaw zmiennÄ… Å›rodowiskowÄ… OPENAI_API_KEY.")
    st.stop()

# Inicjalizacja chatbota i historii w sesji
if "chatbot" not in st.session_state:
    st.session_state.chatbot = NormicaChatbot()
    
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": st.session_state.chatbot.system_prompt}
    ]

# WyÅ›wietlanie historii chatbota
for message in st.session_state.messages:
    if message["role"] == "system":
        continue  # Nie wyÅ›wietlamy wiadomoÅ›ci systemowych
    elif message["role"] == "user":
        st.chat_message("user").write(message["content"])
    elif message["role"] == "assistant":
        if "content" in message and message["content"]:
            st.chat_message("assistant").write(message["content"])

# Panel boczny z informacjami
with st.sidebar:
    st.subheader("ğŸ“ O aplikacji")
    st.write("""
    Normica to inteligentny asystent chatbot specjalizujÄ…cy siÄ™ w normie EN 301 549 
    dotyczÄ…cej dostÄ™pnoÅ›ci ICT (Information and Communication Technology).
    
    Wykorzystuje LangChain i model LLM do zapewnienia dokÅ‚adnych i pomocnych odpowiedzi 
    na pytania dotyczÄ…ce standardÃ³w dostÄ™pnoÅ›ci.
    """)
    
    st.divider()
    
    # Opcje konfiguracji modelu
    st.subheader("âš™ï¸ Konfiguracja")
    model_options = {
        "gpt-4o": "OpenAI GPT-4o",
        "gpt-4-turbo": "OpenAI GPT-4 Turbo",
        "gpt-3.5-turbo": "OpenAI GPT-3.5 Turbo"
    }
    
    selected_model = st.selectbox(
        "Model jÄ™zykowy:",
        options=list(model_options.keys()),
        format_func=lambda x: model_options[x]
    )
    
    temperature = st.slider(
        "Temperatura (kreatywnoÅ›Ä‡):", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.0, 
        step=0.1
    )
    
    if st.button("Zastosuj ustawienia"):
        st.session_state.chatbot.change_model(selected_model, temperature)
        st.success(f"Zmieniono model na {model_options[selected_model]}")
    
    st.divider()
    st.write("Â© 2025 Normica")

# Pole do wprowadzania tekstu
prompt = st.chat_input("Zadaj pytanie o normÄ™ EN 301 549...")

if prompt:
    # Dodaj wiadomoÅ›Ä‡ uÅ¼ytkownika do historii i interfejsu
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    
    # PokaÅ¼ spinner podczas generowania odpowiedzi
    with st.spinner("Normica myÅ›li..."):
        # UÅ¼yj chatbota do wygenerowania odpowiedzi
        response = st.session_state.chatbot.process_message(
            st.session_state.messages,
            prompt
        )
        
        # Dodaj odpowiedÅº do historii
        st.session_state.messages.append(response)
        
        # WyÅ›wietl odpowiedÅº
        st.chat_message("assistant").write(response["content"])
